> DB가 데이터를 저장하는 방법과 데이터를 요청했을 때 다시 찾을 수 있는 방법
> 

`개발자가 좋은 성능을 내게끔 엔진이 내부에서 수행되는 작업에 대해 대략적인 개념이 필요하다`

```jsx
DB에서 특정 키의 값을 효율적으로 찾기 위해서는 다른 데이터 구조가 필요하다
그러므로 색인의 구조를 살펴보고 여러 색인 구조를 비교하자
```

## 색인

- 일반적인 개념은 어떤 부가적인 메타데이터를 유지하는 것
- DB 내용에 영향 X, 단지 질의 성능에만 영향
- 쓰기(Insert) 과정에서 오버헤드 발생
- 어떤 종류의 색인이라도 쓰기 속도를 늦춘다

## 해시 색인

- Key-value 형태의 **hash map** 으로 구현
- 일반적이고 복작합 색인을 위한 구성 요소로 유용
- 키를 데이터 파일의 바이트 오프셋에 매핑
- 메모리에 유지하기 때문에 고성능 읽기, 쓰기를 보장
- 키의 값이 자주 쟁신되는 상황에 적합

**Log-structured** 형식으로 데이터를 저장하면, 매번 새로운 데이터가 추가됨으로 디스크 공간이 부족해진다.

디스크 공간을 해결하기 위해 특정 크기의 **Segment**로 나누고, 나눠진 파일에 대해 **Compaction**을 수행하여 한다.

- Compaction?
    
    중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것을 의미
    

`범위 질의에 효율적이지 않다`

`메모리에 저장해야 함으로 키가 너무 많으면 문제가 된다`

## SS 테이블과 LSM 트리

위에서 설명한 **해시 색인**에서 Key로 정렬하는 것

이처럼 정렬된 형식을 **Sorted String Table** 즉 **SS 테이블** 이라고 한다.

해쉬 색인과 다른 점은 세그먼트 파일 내 Key 값이 한개만 존재한다.

- 이로인해 컴팩션 과정은 이미 보장되어 있다
    
    여러 세그먼트 파일을 병합정렬을 통해 최신화된 세그먼트 파일이 생성된다.
    

정렬로인해 모든 Key의 색인을 유지할 필요가 없다.

- 범위 질의 검색 시 **SS 테이블**에 저장된 Key값을 통해 검색이 가능하다
    
    

새로운 쓰기가 들어오면, 인메모리(**memtable**)에 저장을 하고 **memtable** 용량이 임곗값보다 커지면 **SS 테이블**에 Key-value를 적재 후 **memetable**에서 삭제 시킨다.

여기서 적재한다는 뜻은 파일(**Segment**)로 저장한다

읽기 요청이 들어온 경우 **memtable**에서 조회 후, 그 다음 최신 **Segment**에서 찾는 순서로 진행된다

## LSM 트리

정렬된 파일 병합과 **Compaction** 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라 부른다.

DB에 존재하지 않는 Key를 찾는 경우 느릴 수 있다. **memtable → 최신 Segment → 이전 Segment**

위 순서로 가장 오래된 **Segment**까지 거실러 올라감으로 이를 최적화하기 위해 **Bloom filter**를 추가로 사용한다.

**SS 테이블**을 압축하고 병합하는 순서와 시기를 결정하는 다양한 전략이 있다.

- 크기 계층
    - 상대적으로 좀더 새롭고 작은 SS 테이블을 상대적으로 오래됐고 큰 SS테이블에 연이어 병합
- 레벨 컴팩션
    - Key 범위를 더 작은 SS테이블로 나누고 오래된 데이터는 개별 ‘레벨’로 이동

## B 트리

가장 널리 사용되는 색인 구조

고정된 블록이나 페이지로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기를 한다.

한 페이지는 B 트리의 **루트(root)**로 지정된다. 색인에서 키를 찾을려면 루트에서 시작한다.

페이지는 여러 키와 하위 페이지의 참조를 포함한다. 각 하위 페이지는 키가 계속 이어지는 범위를 담당하고 참조 사이의 키는 해당 범위 경계가 어디인지 나타낸다.

최종적으로는 개별 키(leaf page)를 포함하는 페이지에 도달한다. 이 페이지는 각 키의 값을 포함하거나 값을 찾을 수 있는 페이지의 참조를 포함한다.

B 트리의 한 페이지에서 하위 페이지를 참조하는 수를 분기 계수라고 부른다.

## B 트리와 LSM 트리 비교

LSM 트리는 보통 쓰기에서 더 빠른 반면 B 트리는 읽기에서 더 빠르다.

LSM 트리에서 더 느린 이유는 각 컴팩션 단계에 있는 여러 가지 데이터 구조와 SS 테이블을 확인해야 하기 때문이다.

LSM 트리는 보통 B 트리보다 쓰기 처리량을 높게 유지할 수 있다.

상대적으로 쓰기 증폭이 더 낮고 트리에서 여러 페이지를 덮어쓰는 것이 아니라 순차적으로 컴팩션된 SS 테이블 파일을 쓰기 때문이다.

LSM 트리는 압축률이 더 좋다. 보통 B 트리보다 디스크에 더 적은 파일을 생성한다. B 트리 저장소 엔진은 파편화로 인해 사용하지 않는 디스크 공간 일부가 남는다.

LSM 단점으로는 컴팩션 과정이 때로는 진행 중인 읽기와 쓰기의 성능에 영향을 준다는 점

컴팩션의 또 다른 문제로는 높은 쓰기 처리량에서 발생한다. 대역폭은 유한함으로 단순 쓰기와 **memtable**을 디스크로 방출과 컴팩션 쓰레드가 대역폭을 공유해야 한다.

B 트리의 장점은 각 키가 색인의 한 곳에만 정확하게 존재한다는 점이다. 로그 구조화 저장소 엔진은 다른 세그먼트에 같은 키의 다중 복사본이 존재할 수 있다.

## 트랜잭션 처리나 분석?

- online transaction processing, ***OLTP***
    - Web application에서 발생하는 transaction 데이터
- online analytic processing, **OLAP**
    - **OLTP**에서 발생한 데이터를 정리 가공 후 저장
    - Data warehouse
    - 사용자 입장의 DB가 아닌 비지니스 분석가가 사용
    - **OLTP** 시스템보다 훨씬 더 적은 수의 질의를 다루지만 각 질의는 대개 매우 다루기 어렵고 짧은 시간에 수백만 개의 레코드를 스캔해야 한다.
    - 칼럼 지향 저장소 및 칼럼 압축을 통해 데이터를 관리